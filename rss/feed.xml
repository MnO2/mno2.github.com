<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Paul Meng's Blog</title>
    <link href="https://blog.paulme.ng/rss/feed.xml" rel="self" />
    <link href="https://blog.paulme.ng" />
    <id>https://blog.paulme.ng/rss/feed.xml</id>
    <author>
        <name>Paul Meng</name>
        <email>me@paulme.ng</email>
    </author>
    <updated>2019-10-20T00:00:00Z</updated>
    <entry>
    <title>最近讀的一些投資方面的讀物</title>
    <link href="https://blog.paulme.ng/posts/2019-10-20-%E6%9C%80%E8%BF%91%E8%AE%80%E7%9A%84%E4%B8%80%E4%BA%9B%E6%8A%95%E8%B3%87%E6%96%B9%E9%9D%A2%E7%9A%84%E8%AE%80%E7%89%A9.html" />
    <id>https://blog.paulme.ng/posts/2019-10-20-%E6%9C%80%E8%BF%91%E8%AE%80%E7%9A%84%E4%B8%80%E4%BA%9B%E6%8A%95%E8%B3%87%E6%96%B9%E9%9D%A2%E7%9A%84%E8%AE%80%E7%89%A9.html</id>
    <published>2019-10-20T00:00:00Z</published>
    <updated>2019-10-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>讀得有點雜，不過論文方面讀到比較深刻的就是</p>
<ol type="1">
<li>Investing in the Unknown and Unknowable</li>
</ol>
<p>作者是 Larry Summers 的老師，自己本身也是投資人，基本上是一篇他對於投資的一些觀察，成功的人基本上都是在處理 Unknown 跟 Unknowable 情況計算良好並控制好風險的人，然後只要有正向的高倍率的 Optionality 發生，就能賺到許多錢。在投資的許多場合，機率這個思考框架根本是沒有用的，試想要如何評估將來二十年內自動車大量普及的情況的機率是多少，或是另外一個 911 發生的機率是多少，幾乎是不可能的。而且還有大量黑天鵝事件。所以要根據每個個別情況衡量是否有不對稱性可以利用。然後在能夠辨別跟跟隨領域菁英的時候也不用羞於抄襲別人的投資。</p>
<p>至於給投資人的信主要就是從下面幾個投資人開始讀，不過太長了還沒讀完。我特別喜歡 Michael Burry 因為他也是從 Nobody 開始，比較有參考性。而 Ben Graham 還有 Walter Scholoss 的體系因為分散的關係比較不會害人。Warren Buffet 是有很多智慧但越深入了解就覺得他把一些沒那麼輕鬆的事講得有點輕鬆。不清楚的人會被害到。</p>
<ol type="1">
<li>Warren Buffet 合夥人時期</li>
<li>Ben Graham</li>
<li>Michael Burry</li>
<li>Walter Schloss</li>
<li>Brookfield</li>
</ol>
<p>另外也聽了知名量化基金 AQR 有一個 podcast 的訪談。就是量化跟人腦到底誰的績效整體比較好。結論是沒有什麼差別。但量化是贏在系統穩定，穩定的小贏累積出來。而人腦就是靠打中全壘打。量化的好處也是比較沒有人腦情緒的干擾。但同時一個重要的點是要在你的系統出問題的時候你能夠知道到底是暫時不 work，還是說你的系統失效了。Ed Thorp 在訪談中有說過，你必須事先定義你系統的容錯率，如果你出現了意外的大賺跟大虧損都要反省你的系統是不是有問題。</p>
<p>我覺得 Seeking Alpha 上 Ruerd Heeg 定義的四種策略是不錯的，也是 Ben Graham / Joel Greenblatt 那種人腦跟簡易量化混合的方式，</p>
<ol type="1">
<li>Qualitative Microcap</li>
<li>Low EV/EBIT, EV/EBITDA</li>
<li>Net-net</li>
<li>Falling knife</li>
</ol>
<p>在長期來講，最好的還是雪球股，也就是 Qualitative Microcap。在他還小還沒被發現的時候買進他，為什麼要從小的挑是因為，流動性高的已經有太多機構參與，人家每天在看是看不贏別人的，Microcap 太小大資金的是看不上的，而且美國有規定股價太低的話機構沒辦法投資，是一個老舊的法規幫助機構的手腳，而一般散戶也不會注意到 Microcap。雪球股難的地方是你需要在你的領域超強，看出別人看不出的細節跟未來。要不然你就是要去超冷門的地方做。並且需要時間去累積，一直讀資料等等，所以這是長期的目標。短期內先盡量比較容易看懂的或是軟體產業。</p>
<p>而 2,3,4 都是比較偏量化的策略，是有研究論文支持的，如果能在全球法規足夠完善的地方去分散小部位，統計上來講應該是勝率夠高的。用量化的好處是不會做出太笨的事，然後也不會花太多時間，screener 篩出來後還是會看一下 corporate governance 這塊，如果沒太大問題就可以考慮。這樣我人腦的部分只要先練習出比人家更能看出 corporate governance 的問題就能贏過市場上大部分人，而 corporate governance 這一塊也是機構的機器人還無法量化的部分，所以暫時不會被機器人打敗。越涉及到 Unknown and Unknowable 的部分就越不會被量化策略基金威脅到。</p>
<p>當我閱讀越多的感想，我越覺得除了少數的例外，成功的投資人都是成功的生意人。其實投資也是在拚生意的眼光，就算是做房地產，我知道有一派的投資客也是靠老屋翻修，或是翻修成社區型住宿來賺取比較高的報酬，畢竟房地產也是有他的邏輯，不可能永遠無腦資金行情上漲。我看到賺的好的幾乎都不是純的投金錢而已，都是由翻修等動作的經營本質。而股票中 Activist 的行動也是類似，採取經營權把不適合的管理層換掉來解放價值，甚至像是 Carl Icahn 就有養自己專門的團隊在拿下企業後去整頓。而巴菲特用保險公司去投資 Float，也只是把保險公司的本質做到最完善，很多人想要仿照買了保險公司想如法炮製但卻失敗，因為管不好保險公司。新一代的人我有看到不用保險公司而用 Domain Name 註冊公司，也就是 SaaS 公司來達到同樣的目的，也是先收錢在辦事，但比起經營保險公司簡單很多，是蠻聰明的做法。</p>
<p>希望有毅力定期寫讀物心得..</p>
]]></summary>
</entry>
<entry>
    <title>Kelly Criterion 與 Portfolio Management 的思考</title>
    <link href="https://blog.paulme.ng/posts/2019-10-19-kelly-criterion-%E8%88%87-portfolio-management-%E7%9A%84%E6%80%9D%E8%80%83.html" />
    <id>https://blog.paulme.ng/posts/2019-10-19-kelly-criterion-%E8%88%87-portfolio-management-%E7%9A%84%E6%80%9D%E8%80%83.html</id>
    <published>2019-10-19T00:00:00Z</published>
    <updated>2019-10-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>最近一直對 Portfolio Management 方面還有看事情角度有蠻多疑問，看了一些投資機構的文章以及去爬知名投資人的寫作，最終的結論還是要看每個人的個性。不過從一些從 Kelly Criterion 角度出發的<a href="https://intrinsicinvesting.com/2019/09/03/position-sizing-why-conviction-matters/">文章</a>還是多少有些幫助的。這篇把看過的一些東西記錄下來。</p>
<p>Kelly Criterion 是被 Monish Pabrai 寫進書裡才比較出名，很多知名投資人都有用。最初也是 Ed Thorp，一個戰勝賭場的 MIT 教授發揚光大的。主要是用在賭場中，但他用在投資裡面有缺陷，主要因為</p>
<ol type="1">
<li>投資許多情況下機率的事件分佈無法衡量</li>
<li>回報也是未知數，並不見得是贏了是固定的倍數</li>
</ol>
<p>所以現實中多辦用到 1/4 Kelly 就已經很多了。甚至有變形，使用最多願意輸的錢 * Kelly 算出來的比例。</p>
<p>而減小 Kelly 的倍數而不要下過大的賭注是因為整個市場（不只股市）有厚尾跟黑天鵝的特性。有一些投資人就是專門做黑天鵝的，像是 Anti-Fragile 的作者 Nassim Taleb 他之前就有一個基金是做 Options 來賭黑天鵝，他也是這麼發家的。另一個算是做黑天鵝的是索羅斯，而且他又是賭特別難以捉摸的總體經濟部分，他也有對於世界運作的一套反身性哲學。他們的系統都太難學了，運作的方式也是要大資金一般人根本沒辦法複製。</p>
<p>有一個容易忽略掉的一點就是漏看了細節。儘管巴菲特跟他風格的投資人如果是非常確定的時候會下大注，但一個關鍵點就是他們下大注常常其實也是為了拿到董事會的席位，獲得內線跟投票權，甚至是決定權。這樣其實是更安全的，因為你找到機會後可以然公司照你的方向改變，而不是希望公司的管理層聽你的建議而已。這是我這次在一篇一篇看巴菲特早年合夥人時代的信發現的。他的 Sanborn Map Corp. 就是這樣操作。而對於資金量沒有辦法買到董事席位的投資人，就算你是搭其他 Activist Investor 的順風車，你也應該要不要賭過大的部位因為你沒有董事會投票權，你的生存是操在別人手上。並且加入一些技術分析的手段來保障不可知的情況，像是別人有內線在市場上倒貨。我以前對技術分析覺得不合時宜，因為</p>
<ol type="1">
<li>現在都是機器人量化了，技術指標那些在北美市場早就被套利完了，幾乎是不太可能有用</li>
<li>對於流動性股票強的股票也因為關注過多，資訊很快就會反應。不做毫秒級根本沒有意義。但那些 high frequency trading 的機構都已經做完了。</li>
</ol>
<p>這次看到 Michael Burry 早年在 MSN 的文章，我還蠻驚訝他居然會用簡單的技術分析當作進入點還有加入停損。他說是因為 practical reasons，主要是避免 fundamental 分析的缺陷還有自己可能的錯誤，在他用了簡單的 trading 規則加上停損規則之後，他的 portfolio 沒有因為單一部位爆炸而爆炸過。所以可以推測在超早期他曾經也因為單一部位爆炸而讓整個 portfolio 炸過。只有對於像是 Asset play 還有雪球股他說不會停損。對於他的說法我覺得很合理。</p>
<p>而 Monish Pabrai 的作法就是儘管再看好也只會下 10%，不過我之前看到他 AER 的部位都 40% 了，但那應該是漲上去的結果，另一方面也是他並不是所有部位都在美國，我們並不知道他美國以外部位的大小。所以他的做法其實比較像是最多願意輸的錢 * Kelly 算出來的比例。</p>
<p>有想到更多的話再更新..</p>
]]></summary>
</entry>
<entry>
    <title>所謂量化與質化的思考</title>
    <link href="https://blog.paulme.ng/posts/2019-10-18-%E6%89%80%E8%AC%82%E9%87%8F%E5%8C%96%E8%88%87%E8%B3%AA%E5%8C%96%E7%9A%84%E6%80%9D%E8%80%83.html" />
    <id>https://blog.paulme.ng/posts/2019-10-18-%E6%89%80%E8%AC%82%E9%87%8F%E5%8C%96%E8%88%87%E8%B3%AA%E5%8C%96%E7%9A%84%E6%80%9D%E8%80%83.html</id>
    <published>2019-10-18T00:00:00Z</published>
    <updated>2019-10-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>看到在 Facebook 上有對於 Bill Nygren 回覆關於有什麼他希望他當年開始投資的時候希望他自己能知道的事。他的回答大致是說希望對看中本質而不要只依賴於量化。在他的經驗裡沒有一個完全依靠量化模型賺錢的。</p>
<p>這剛好也是我最近在思考的，AQR 之前也有一集 Podcast 講量化跟質化哪個比較好。不過我注意到大家在講量化的時候沒有一個統一的定義。金融領域之中真的充滿了缺乏嚴謹定義的名詞跟 Misnomer。 我覺得要討論必須對【量化】這個東西下定義，討論才會比較均衡。同樣的·問題拿去問 Jim Simons 跟 Ed Thorp 大概會得出完全不同的答案。</p>
<ul>
<li>Jim Simons 早期也是做 Fundamental 的，但他因為一些經歷後覺得質化分析不夠可靠，最後跟他研究團隊最後決定全部走量化</li>
<li>Edward Thorp 早年其實有跟巴菲特接觸過，那時候它就有預測他會變成全美最有錢的人，但他因為覺得自己擅長量化，又不想整天搞財報拜訪公司，所以就自己最後就變成統計套利的始祖。</li>
</ul>
<p>當然，很明顯 Bill Nygren 的量化跟 Jim Simons, Edward Thorp 的量化是完全不同的東西。我覺得 Bill Nygren 也只能說是他自己的優勢他做不到。但我覺得對於數學天才還是可以做得很好。而且質化還是要面對各種人性的弱點，只是這些弱點不好顯現，或是這些說話的人天生比別人要強。最終還是回歸你【相信】你自己的優勢在哪裏。但說實在相信也是容易造成 confirmation bias，也許就是想要這麼相信所以才找跟你體系相近的投資人的答案。</p>
<p>隨著科技的演進，我相信量化跟質化的差異會越來越小，以前覺得只有人能判斷的部分都可能隨著自然語言處理的進步而進入量化系統中，有聽說華爾街也是有投資一些這方面的資金在分析 twitter 上面的舉動的。只要研究有一天能夠順利做出 encode 人類的邏輯進電腦的邏輯，那純粹人的質化優勢會越來越小。</p>
<p>我目前的思考是，人類質化在強人工智慧來臨之前。他其實很重要的一點是能判斷什麼東西儘管沒看過，但可以用邏輯判斷有違於常識。這就是有一個判斷基準說某一套邏輯不會 work，畢竟以金融市場這樣會因參與者行為改變的系統（也就是索羅斯說的反身性），沒有永遠 work 的系統。而 Ed Thorp 說過要用一個系統非常重要的是你必須事先設定一個判斷說什麼條件發生的時候你的系統有問題，而一般人用量化系統的時候沒有考慮這層（先不說亂用 R-sqaure 的結論），而那是靠人腦的質化研究可以簡單提供的。</p>
]]></summary>
</entry>
<entry>
    <title>目前我看懂的幾種辨別投資機會的方式</title>
    <link href="https://blog.paulme.ng/posts/2019-10-15-%E7%9B%AE%E5%89%8D%E6%88%91%E7%9C%8B%E6%87%82%E7%9A%84%E5%B9%BE%E7%A8%AE%E8%BE%A8%E5%88%A5%E6%8A%95%E8%B3%87%E6%A9%9F%E6%9C%83%E7%9A%84%E6%96%B9%E5%BC%8F.html" />
    <id>https://blog.paulme.ng/posts/2019-10-15-%E7%9B%AE%E5%89%8D%E6%88%91%E7%9C%8B%E6%87%82%E7%9A%84%E5%B9%BE%E7%A8%AE%E8%BE%A8%E5%88%A5%E6%8A%95%E8%B3%87%E6%A9%9F%E6%9C%83%E7%9A%84%E6%96%B9%E5%BC%8F.html</id>
    <published>2019-10-15T00:00:00Z</published>
    <updated>2019-10-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>來寫一下我目前的理解。寫作也是為了理清自己的思路。以下要講的都是公開市場的機會，對於像是投資銀行跟 Private Equity 他們的投資及會對於一般人太遠了。我目前看懂的大致分為下面幾種:</p>
<ol type="1">
<li>Organic Growth</li>
<li>Roll-up</li>
<li>Asset Play</li>
<li>Turn Around</li>
<li>Commodity Cycle</li>
</ol>
<h2 id="organic-growth">Organic Growth</h2>
<p>這一類通常都是初學者會接觸的，也是電視名嘴特別愛講的。特別是巴菲特晚期的一些名言透過媒體變得廣為所知後，一大堆投資部落客都愛說自己是遵循巴菲特哲學，滿嘴巴菲特但其實他們九成以上都沒有仔細去研究巴菲特早年 Partnership 的投資模式。不過巴菲特晚期的哲學的確是王道，這一類也的確都是優質的企業，如果可以用合理或是便宜的價格買到真的就是不要輕易放掉。只是主要的問題是等到你知道的時候都已經漲上去了。譬如說，現在 Visa 跟 Google 的簡易指標都很高</p>
<ul>
<li>Visa: EV/EBITDA = 25</li>
<li>GOOG: EV/EBITDA = 16</li>
</ul>
<p>EV/EBITDA 大致代表的意義是付出一定的價錢買的的現金流或是收入回收所需要的時間。跟 P/E 不同的是 EV 計入了債權一起進去考量，並且扣點 Balance Sheet 上的現金，用會計上的收入扣掉折舊等等來當作現金流的快速計算。所以 EV/EBITDA = 25 就是我花錢買 Visa 的股票假設經營狀況不變的情況下至少要 25 年才能回本。在沒有爆發性成長的前提下這是一個很貴的價錢。根據經驗還有我聽其他投資人的分享，一般來說都是 EV/EBITDA = 10 是合理價，EV/EBITDA &lt;= 8 是便宜，EV/EBITDA &lt;= 5 是大甩賣。不過也是要看市場，在日本的話企業經營都比較保守，帳上會有很多現金，因此經常會看到 EV/EBITDA &lt;= 8</p>
<p>雖說也是可以追高，特別是現在有指數基金提供動能的情況下追高的動能有可能還是可以運作好一陣子，這些也都是好企業，但這就表示你的投資邏輯是奠基於</p>
<ol type="1">
<li>業績會不斷如預期增長，甚至超越</li>
<li>之後有人願意用更高的價錢接受</li>
</ol>
<p>這預測的難度其實是不低的，只要你預測出錯就是除了一個很貴的價錢卡在那邊。特別是大企業多少投資法人請最好的人全職去研究，就算不說法人通常明顯的優勢大家都看得出來，也就是你沒有特別有優勢。你要能夠贏過其他人，通常有可能的就是</p>
<ol type="1">
<li>這是你的本業，而且你是行業中的佼佼者。</li>
<li>因為一些因素你先看到了，可能是因為你看到的生意是地區性的而你就住在那邊。</li>
<li>你對行業也有足夠了解。</li>
</ol>
<p>衡量競爭優勢跟成長性都沒有想像中容易。隨著時代轉變，所謂競爭優勢也不斷出現非傳統的護城河，像是 Netflix。但多多少少企業不到短短幾年又被後來者追過。所以巴菲特才會喜歡消費股，因為被科技演進淘汰的機率較小。這一點會牽扯到你抱不抱得住股票</p>
<ul>
<li>過程並不平順，而且人會不斷有新的想法或改變想法而抱不住。就算職業投資人也非常難。</li>
<li>外行人不好評估跑道多長。</li>
<li>非職業投資人的話一生能抓到一兩個 10 bagger （10 倍股) 就不錯了</li>
</ul>
<p>針對如上的各個困難點，要能夠彌補的話並沒有什麼好方法</p>
<ol type="1">
<li>盡量挑你本業相關的，或是相近的產業。</li>
<li>除非是金融危機千載難逢的機會你可以用低價買到好的大企業，不然 Micro-cap or Nano-cap 也是有機會的，可以避開跟法人做對手。只是盡量在歐美法治公司治理比較好的地方比較不會碰到老千，香港跟台灣的問題就是公司治理問題會讓人不敢碰小企業。</li>
</ol>
<h2 id="roll-up-leveraged-roll-up">Roll-up / Leveraged Roll-up</h2>
<p>跟自然地業績成長不同，這一類型的公司是不斷透過收購合併來成長。最有名的就是 John Malone 的 TCI 還有他建立的 Liberty Complex。巴菲特投資 Liberty Complex 也是有頗長的歷史，如果把大大小小合併起來的話可能佔他頭幾大部位。</p>
<p>這類的玩法原理說起來很簡單，但實際做起來不容易。要簡單解釋的話就是他很類似某一類房地產玩家的做法。</p>
<ol type="1">
<li>我選好適合出租的房子，背槓桿買下房子改裝出租。如果自己一開始出 20% 股債比就是 1:4。也就是如果租金收入對房價是 4% 的話 (ROA = 4%)，那 ROE 就放大成將近 20%。不及 20% 是因為還要付利息。</li>
<li>出租的租金足夠多，而且穩定。就可以依靠他來付房子的貸款，然後長期降槓桿。如果付掉一半的話股債比就降到 1:1，ROE 也會下降到約 10%</li>
<li>如果這時候房子的房價太高了，那就把房子脫手賺取泡沫的估值價差。</li>
<li>如果沒有泡沫，同時有看到其他不錯適合出租的物件，就用現在手上的房子再貸出更多錢買下房子出租，回到步驟一如此重複。ROE 又回到 20% 以上</li>
</ol>
<p>同一套玩法也可以拿來套在做企業上，而這就是 John Malone 的玩法。但這個玩法有很多前提。</p>
<ol type="1">
<li>現金流的穩定度很重要，因為你要拿來付債息。</li>
<li>降息的環境也重要，這跟槓桿的資金成本密切相關。</li>
<li>業務要有整合性，房子的話是相對容易。但企業整合的話會有文化的問題。員工可能會反彈。你要整合業務省錢的話，也是會有原有企業動機不足的問題。</li>
<li>產業要足夠零碎讓你有整合的空間，並且業務不複雜。太複雜的業務整合不易。</li>
</ol>
<p>失敗的案例就是 Bill Ackman 曾經的最大持股 Valeant。最後爆掉也是因為整合後提升藥價受到整體社會反彈。而且後期付出收購企業的錢越來越高，因為產業不夠零碎，人家知道你的玩法後就提價讓你收購價高到無法負荷。</p>
<p>通常房地產在社會發展前期會有這樣發展的空間，房地產商也通常是這樣起家的，從小做到大，只是他們不是用出租而是用販賣物件的方式風險，但槓桿的原理是類似。但因為也是這樣因為槓桿現金流不足爆掉的風險會更大，多半在經濟週期後段爆掉也是因為太貪心或沒遠見而沒有適時降槓桿。</p>
<h2 id="asset-play-net-net">Asset Play / Net-Net</h2>
<p>這就是巴菲特的啟蒙者 Ben Graham 所開發出來的一種方法。巴菲特早期在合夥人時期也幾乎都是用這種方法，他是到波克夏時期遇到查理孟格才逐漸轉變投資方式。</p>
<p>這種方法的核心是奠基在邏輯推導，如果一個企業的市值小於他的淨現金部位，也就是【現金 + 待收貨款 + 折價後的存貨跟短期投資 - 所有負債】。那這個企業理論上不應該存在，因為清算還比你繼續經營還划得來。巴菲特早期就靠入股這種企業然後清算賺了很多錢，不是像現在他在媒體上慈眉善目的形象。</p>
<p>計算資產的時候現金跟待收貨款是最好，存貨的話像是流行服飾清算的話就沒什麼價值，但如果是勞力士之類的話二手市場是存在價值的。而其他硬資產像是土地是最好，飛機通常也能賣到五折，在做這架的時候要根據產業不同用不同估算方法。</p>
<p>這種方法的缺陷就是你對企業沒有直接的控制權，除非你想巴菲特直接買到最大持股去影響董事會。所以最初的方法論是你要買一籃子這種企業，而且平均分散在不同產業。搭配上一些基本指標譬如說不要太多負債等等，然後靜靜地等待未知的催化劑，有可能是均值回歸，或是清算，或繼續賠錢而倒閉。 Ben Graham 提倡的是你買入一籃子然後等三年或賺 50% 賣掉。</p>
<p>這種方法的缺點是，現在已經廣為所知，所以在比較有效率的市場都已經被套利完了。剩下就是日本比較多，所以後來就有點拓展到其他方法。</p>
<ol type="1">
<li>公司有隱蔽性資產，譬如公司有一筆很早買的土地，在 Balance Sheet 上沒有根據市價重估。</li>
<li>公司有一些經營危機，但如果分拆賣個 Private Equity 或競爭對手的話，可以賣到比繼續經營好的價錢</li>
</ol>
<p>但這些的缺點都是要有 Active Investors 去處理，因為職業經理人只是打工的，沒有動機去做。因為企業清算或是賣掉了管理層就失業了。比起清算還不如繼續吸血領高薪。而 Active Investors 的能力目標利益是否一致也是很重要。這類型都是理論上會 Work，但最後因為人為因素搞砸的機率也是有。</p>
<h2 id="commodity-cycle">Commodity Cycle</h2>
<p>原物料一個特性是他有週期，而且週期很明顯，如果能夠大致抓對時機耐心等待的話就能夠賺到錢。只是要抓對能夠撐過週期的企業不容易，而某些商品因為是國際性商品，特別難以預測，像是石油就是，因為參與的國家太多，賽局太複雜。俄羅斯，沙烏地阿拉伯，美國，委內瑞拉等等。通常連專家都預測不太準。一般來講都是要搭配總經數據，看到等到確定的信號再投進去，放棄頭尾段只賺中間的部分。股價特性常常是低迷很長一段時間然後暴衝。</p>
<p>但產業中有一些特別的部分，像是有煤業是只賺權利金的部分的企業，也就是他不出資開採，他是幫別人開採然後賺綁定通膨的差價部分，就會比較抗週期。或是有一些開採後的成品有運送成本的限制，像是水泥的原料 Lime Stone，那如果公司是在內陸的話，那就會有對於國際供應的護城河。或是看天然氣裡面擁有的地的開採成本比其他地方都低，那在賽局中大家都不得不擴產賺取現金的時候，他就可以撐比較久，然後在最後的賽局中活下來。</p>
<p>同樣這一類難度也是不低，但好的是你幾乎可以確定會有下一次週期，不像有些產業被革命了就再也回不來了。</p>
<h2 id="turn-around-over-pessimistic">Turn Around / Over-Pessimistic</h2>
<p>這一類很像是買賣二手物品一樣，許多二手物品都有瑕疵，但稍微整理一下都能買到好價錢。如果有在二手拍賣網站像是 Carousell 買賣過東西一樣，就知道有一類二手商整天就在上面看有沒有人大甩賣商品，他用超低的價格撿到，稍微整理一下就可以賣出差價。而股票也是，這類通常都是有些問題的企業，但股價超便宜。如果成功 Turn around 的話，估值修復很容易至少成為 2-bagger 或 3-bagger 股。或是用房地產舉例，說有人開玩笑一百塊錢台幣賣你一棟鬼屋你要不要？有些人不理性不計算就覺得給我鬼屋我也不能住送我也不要，但理性人應該是計算整理後是否能賣出合理價，扣除稅費後是不是比一百塊便宜，可以想見只要價錢夠低，就算是爛物件很高的機率你的推論會是對的。</p>
<p>這類企業有時候跟 Asset Play 重疊，譬如說 Balance Sheet 裡面有其他值錢的投資，可以 cover 掉負債。但很多時候你對產業有些瞭解，知道一些眉角。譬如說在零售業裡面店租是很高的成本，但你發現某家零售業雖然業績下滑但 Operational Lease 裡面是 Cancellable 也就是可以退租不用被合約綁住五年的，如果 Balance Sheet 上面沒有負債的話變成 0 的機率就更低。或是香菸雖然被法規限制，但法規限制的同時，小企業沒辦法付出法遵的成本，所以實際上會造成寡占。或是企業雖然槓桿很高但現金流沒有惡化。並且債券到期日是平均分散的。債多不是問題，流動性才是問題。也有可能是因為減稅或會計規則的變化而大多數人漏算了某部分的資產。如果 CEO / CFO / COO 有自己買進股票並在股東會上透露一些訊息通常會是一個 confirmation。而通常公司業績下降在商業發達的地方都會很有動機拉回來的，畢竟股東不想賠錢，管理層不想失業。最差可能就賣個競爭對手多少回收一些比清算要好的價錢。</p>
<p>但玩這套最好要要在法治跟商業道德比較好，還有 Investor 比較容易介入的地方會比較容易。台灣跟香港有太多公司治理的問題，大陸就更不用說了。而且大陸很多地方政策，法治，公共政策資料也不透明。而且產業跟地區最好分散，這樣比較不會有系統性連動的問題。可參見我講指數基金的問題那篇。</p>
<p>如果你有一籃子，假設股價彼此沒有強相關性。用簡單的數學計算：保守估計平均 3 年內 Turn Around，不然歸零，你如果有 7 成的機率猜對，那期望值如下。</p>
<pre><code>2 * 0.7 + 0 * 0.3 = 1.4</code></pre>
<p>年化報酬率有 12%。你如果有 8 成的機率猜對，那期望值如下。</p>
<pre><code>2 * 0.8 + 0 * 0.2 = 1.6</code></pre>
<p>年化報酬率有 17%。</p>
<p>如果長期關注的話，小部位多做多觀察加大經驗可以隨著交易經驗越來越多，學習越來愈多產業經驗，辨別失敗跟詐騙的情況會越來越準而增加獲勝機率。</p>
<p>比較怕的是有時候你會看到邏輯上特別好的機會而賭大部位，但實際上是 Value Trap，被稱為下一個巴菲特的 Eddie Lampert 就因為 Sears 都死在這裡。包含巴菲特自己都中過好幾個爆掉的投資，Berkshire Hathway 這個殼就是其中一個爆掉的，他把原本業務清算掉變成投資公司。所以有人也認為巴菲特有可能是倖存者偏差。現今巴菲特的左右手 Ted 也是靠賭大的這類企業賭對的而發家的。</p>
<p>經過之前經驗我覺得還是小部位分散多個會比較穩定，這種方式其實有一點像 Morgage Backed Security，慢慢賺讓期望值站在你這邊。然後隨著更多的資訊的揭露 Buying up，就好像玩撲克的時候隨著牌越開越多加賭注一樣。等逆轉了被確定再加一些，但嚴格控制部位上限。</p>
<h2 id="dumped-by-mechanical-device">Dumped by Mechanical Device</h2>
<p>這一類就是某些因為機械性原因而被無條件拋棄，最簡單的就是被 Index delist 的股票，反過來如果被加進 Index 的話也可能漲上許多。或是一些基金因為股票太便宜而不能購買，或是有一些道德因素而必須被清掉。Spin-off 雖然不是機械性的原因，但也很容易因為投資人不熟而無條件賣掉。Joel Greenblatt 就是靠 Spinoff 發家的。</p>
<h2 id="結語">結語</h2>
<p>除了基本的方法論之外，具體的產業知識是很重要的，這些都藏在 CEO 的談話中，或是有些秘密只能反向去推敲，沒有人會跟你講。都是要長期累積，但了解的話勝率會提高不少。</p>
]]></summary>
</entry>
<entry>
    <title>Life Reliability Engineering</title>
    <link href="https://blog.paulme.ng/posts/2019-10-06-life-reliability-engineering.html" />
    <id>https://blog.paulme.ng/posts/2019-10-06-life-reliability-engineering.html</id>
    <published>2019-10-06T00:00:00Z</published>
    <updated>2019-10-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I have the feeling that we have an epidemic of stress, unhappiness and anxiety in the tech industry. It may be due to the working culture, perfectionism or simply because of toxic working environment. You could tell that from the suicide of Facebook employee a couple of weeks back, and Amazon employee in the last year. From time to time I would also experience such kind of tide in emotion in life. In order to tackle this I have developed my own kind of system to keep my mental health in control. And I didn’t find a good way to describe it by metaphor to explain it to another engineer until I am more familiar with the terminology of Site Reliability Engineering.</p>
<p>First, we have to identify catastrophic patterns to cause your system downtime. In life, it means you go depressed, and want to kill yourself, or simply lack of motivation to anything. One important observation is that the stuffs you might consider important are correlated to each other. The life could give you a straight of bloody Marry due to this. One bad thing could lead to the other. Even you are born in a middle-class family and have a good enough income, or slightly better in recent year as a software engineer. Your life could be easily destroyed. It doesn’t have to be financially, if you are depressed and committed suicide even you have billions in bank it is still a checkmate to your life. For example, it could be your marriage affects your work performance and get you fired, and you lose your income. Or it could also be your important partner is sick, it not only costs you a fortune to pay the medical bill if you are living in countries like U.S.A or Singapore, where medical bills are expensive comparing to the median incomes. And since you have financial burden, your significant partners could be tempted to abandon you since they would not like to be involved etc. In order to prevent the chain reaction, you have to manage your “components” to be more resilient against each other, and not be over-confident to have too many components in your life. For example: getting overly leverage financially on your housing but at the same time raising kids, after all raising kids and marriage are liabilities that is off balance sheet. And if you already have components you are reluctant to get rid off, make sure you have insurance covered in a proper way to reduce the over all risks, at least stopping the chain effect when it happens. The best, for sure, to have low liability.</p>
<p>Once you find a way to manage your portfolio of liability, a portfolio of “bomb shelters” or “chambers” where you could find peaceful time to recover is important. Over-stretching on a specific goal is dangerous since if that goal fails your mental health would be seriously damaged. For example, if you would like to climb the ladder of corporate or build a company. You have to go all out but make sure not to over stretch that could cause a total meltdown. If your goal fails, if you still have other goals like playing sports/games where you could find small achievement, that’s a hedge for your mental meltdown when you fail to build a company or climb the ladder. It’s a diversification of your goal, to make sure it’s unlikely that they correlate each other. If your secondary goal is to tied to your kids or partner, due to human minds are not stable. They might not care or understand your situation when you are down for those goals. It could be a shelter but not a reliable hedge. Having nice food is a good one since it’s unlikely that it would be affected by human factors, but having it too often it could hurt your lookings or physical health as well.</p>
<p>Other than the diversification, I find stoicism is also useful to me. Here is a video from Tim Ferriss.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5J6jAC6XxAI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>I am not a fan of what’s been in American main stream culture on the alpha-male like of “Leadership.” Human are not infalable and actually quite easy to be broken. Overly stretching to the image of “confidence” and “overcome your poster syndrome by pretend it until you make it.” would easily make yourself vulnerable to a strike-back. I believe the Newton’s third law of motion applies here as well, if you stretch too much, you are exerting the same magnitude of force in the opposite in the same time.</p>
<p>These are the “tips” or “speculation” that I have in mind for years. It’s not a science or corollary that would be deemed as universal and could be applied any kind of extreme situation (for example, war time or you are put in concentration camp). But at least it kind of works for me in modern time living in big cities.</p>
]]></summary>
</entry>
<entry>
    <title>市值權重指數基金與系統性設計問題</title>
    <link href="https://blog.paulme.ng/posts/2019-10-04-%E5%B8%82%E5%80%BC%E6%AC%8A%E9%87%8D%E6%8C%87%E6%95%B8%E5%9F%BA%E9%87%91%E8%88%87%E7%B3%BB%E7%B5%B1%E6%80%A7%E8%A8%AD%E8%A8%88%E5%95%8F%E9%A1%8C.html" />
    <id>https://blog.paulme.ng/posts/2019-10-04-%E5%B8%82%E5%80%BC%E6%AC%8A%E9%87%8D%E6%8C%87%E6%95%B8%E5%9F%BA%E9%87%91%E8%88%87%E7%B3%BB%E7%B5%B1%E6%80%A7%E8%A8%AD%E8%A8%88%E5%95%8F%E9%A1%8C.html</id>
    <published>2019-10-04T00:00:00Z</published>
    <updated>2019-10-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>前一陣子因為 The Big Short 而出名的 Michael Burry 回覆了 Bloomberg 對於市場看法的信而又引發了網路上一場論戰。因為他的回覆中關於 Index Fund 的說法提到了 “Bubble” 這個詞而許多人擺錯了重點，把重點擺在是不是有 Bubble 這件事。其實他的說法跟之前 Howard Marks 還有 Seth Klarman 提到的並沒有不同，其實關鍵的重點在於結構設計，而每個結構設計跟實體工程一樣都有他的極限在，特別是在金融市場中因為結構承重量或容錯量是不可見的，涉及抽象的概念。雖然我完全同意 Micael Burry 的說法，但我一直想不到一個好的比喻跟一般人解釋這件事。直到我前幾天看到 yinwang 關於自動駕駛責任的<a href="http://www.yinwang.org/blog-cn/2019/09/30/autopilot-responsibility">文章</a>。我覺得解釋得非常清楚，而同樣的邏輯謬誤也是可以套用在市值權重指數基金擁護者的回覆上。</p>
<p>要討論這件事涉及兩個層面</p>
<ol type="1">
<li>為什麼用【市值權重指數基金拿到的是市場報酬】不足以回應 Michael Burry 點出的風險？</li>
<li>市值權重指數基金的缺陷在哪？什麼情景下會觸發？</li>
</ol>
<p>首先用一個例子來說明第一點。在今年初發生了 Boeing 737 MAX 因為設計不良而造成的事故。一時間人心惶惶，而各國政府也相繼搬出政策禁飛 Boeing 737 MAX。為什麼大家會擔心這件事？不是說 “平均” 來講，發生空難的事件極低嗎？ 機率上來講你死在去機場的路上是遠高於你發生空難的機率。這主要的問題是因為 Boeing 737 MAX 有共同的因素驅動，也就是設計的缺陷。</p>
<p>就機率來解釋的話，就是</p>
<pre><code>P(其它 Boeing 737 MAX 墜機  | 一架 Boeing 737 MAX 墜機)</code></pre>
<p>高於</p>
<pre><code>P(其它非 Boeing 737 MAX 墜機 | 一架非 Boeing 737 MAX 墜機)</code></pre>
<p>因為他們不是類似於獨立事件。而是有共同的缺陷。假如每一家航空公司全部都是提供 Boeing 737 MAX 的話，說我身為一個個體明天搭的飛機墜機的機率趨近於平均發生空難的機率一點意義都沒有，因為平均的結果是大家一起因為起飛後因為設計的缺陷造成機頭直接往下墜毀死亡。</p>
<p>所以說【市值權重指數基金拿到的是市場報酬】並不足以回應。正確的回應要解釋為什麼市場報酬背後沒有共同驅動因素造成大家一起死的結果。這在大多數時候是對的，畢竟市場報酬是買方跟賣方資金平衡投票出來的，而且市場中每個人的想法不同，就好像是不同設計的飛機一樣。所以大多數時候市場的驅動的因子沒有共同背後的因素驅動。但接下來解釋的第二點，我會說明在某種特殊情況底下是有可能發生的，也就是市場上的參與玩家是同一個想法佔大多數的時候，而指數權重基金佔大多數也就是其中一個實現。</p>
<p>要了解第二點必須說明市值權重指數基金的運作，這邊舉一個簡單的小例子說明。台灣人很愛買房子出租，所以用房子來舉例，</p>
<p>今天市場中有三種分十年折舊的房子可以帶來租金收入，然後市場裡面有四個投資人 A, B, C, D</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">房子</th>
<th style="text-align: center;">年租金</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">i</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">ii</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">iii</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<p>期間是 10 年，十年後房子價值歸零。市場無風險利率是不會動的 1%，而對於房地產的投資人 A, B 風險利率要求是 2%，加上通膨 3% 折現率共 5%。那這些房子在他們兩個人間的平衡價錢應該是多少呢？用十年的 DCF 可以得到</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">房子</th>
<th style="text-align: center;">價格</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">i</td>
<td style="text-align: center;">7.72</td>
</tr>
<tr class="even">
<td style="text-align: center;">ii</td>
<td style="text-align: center;">15.44</td>
</tr>
<tr class="odd">
<td style="text-align: center;">iii</td>
<td style="text-align: center;">77.22</td>
</tr>
</tbody>
</table>
<p>而投資人 C, D 決定採取不一樣的觀點，不用類似 DCF 的方式衡量，他們決定編制 FOOBAR 市值權重指數，這個指數就是</p>
<pre><code>i 的市價 * (7.72 / 100.38) +
ii 的市價 * (15.44 / 100.38) +
iii 的市價 * (77.22 / 100.38)</code></pre>
<p>他們把他們的錢加起來成立市值權重指數基金，把他們共有的錢 100.38 照上面比例分配買。也就是 i 買 7.72 塊， ii 買 15.44 塊， iii 買 77.22 塊。所以投資人 C, D 認定的價值不是根據衡量物件本身，而是因為市場中其他人的價錢而分配他們的錢的分配。加入今天 A, B 覺得 iii 其實收不到 10 塊的年租金，其實只能收到 2 塊。那就會變成 15.44 塊。那 C, D 就會跟著把 iii 賣掉。因此你可以看到一般所謂的市值權重指數基金就是一種 Trend Following 的策略，是因為市場中其他對價值做出反應的人的定價而跟隨。在這個例子中，當 C, D 反應過來的時候，他們賣的價錢可能會低於 15.44 塊。因為他們的對手只有 A 跟 B。而 A, B 只願意用低於 15.44 塊的價格收，不賣的話就違背了他們指數的規則，所以他們一定要賣，這是機械性訂死的。 為了要賣掉他們就不得不降價，這邊的例子只有 C, D 兩個個體的資金，但你可以想像賣方是這個的 100 倍, 1000 倍然後【同時】想要賣的情況，也就是會造成 race to the bottom。最後平衡價可能遠遠低於 15.44，也許 7, 8 都有可能。</p>
<p>但市場有趣的地方就是上述情況又不是鐵定會發生。假如今天反而是 A, B 突然都變調，也投入 C, D 的指數基金。市場中就不再有人用 DCF 去定價了。所有人都認為權重永遠都是如下：</p>
<pre><code>i: (7.72 / 100.38) 
ii: (15.44 / 100.38)
iii: (77.22 / 100.38)</code></pre>
<p>整個 price discovery 的機制就不見了，不管底下的實際能收到的租金有多少，就是這樣定價，所以說股價都是所謂人類基金管理者亂炒作這說法並不公平，市值權重指數是一種跟隨策略，沒有人類基金管理者他也是不會動的。但這並不是一個穩定的平衡，遲早有人會跳出來點出國王的新衣，然後前面崩毀的情況就會發生。</p>
<p>從上面的邏輯推導與立論可以知道，市場大多數人都在使用某個系統時，而那個系統又因為一些背後共同問題造成時，平均就是大家一起平均死。沒錯，你拿到平均的結果，但你還是死了。但同時，請不要滑坡推論就說 Boeing 或是市值權重指數基金就是該死，身為渺小個體我們應該完全摒棄，因為</p>
<ol type="1">
<li>統計上 Boeing 跟 Airbus 造的飛機比起你自己亂造的飛機要強，儘管 Boeing 737 MAX 有問題。</li>
<li>統計上 Boeing 跟 Airbus 造的飛機比起你自己請的飛機廠商也要強，儘管 Boeing 737 MAX 有問題。</li>
</ol>
<p>但反面來說</p>
<ol type="1">
<li>統計上有瑕疵的立論並不能因此讓我不擔心 Boeing 737 MAX 的結構性問題，除非你能舉出有說服力的邏輯推論說明我舉出的情況不用擔心，因為儘管機率不高或是未知，但我一旦中了就死了。同樣對於市值權重指數基金也是，這關係到許多人畢生的積蓄。</li>
</ol>
<p>我想聲明，市值權重指數基金是非常偉大的發明，他讓大多數不懂金融的人都有機會分享到果實，能承受的資金量也非常巨大，至今都沒發生問題。</p>
<p>我並不是鼓勵說就不要使用指數基金，但與此同時，因為過去沒發生問題而認為以後也不會發生問題，不去用正確的邏輯回應問題。這種過度膨脹的心理而不去理解市值權重指數基金的結構所潛藏的缺陷並提醒大家，在我看來跟那些設計各種金融工程工具但不去點出工程極限的人沒有兩樣，都是不負責任的。</p>
<p>最後安插一個軼聞。Michael Burry 在 2000 年就成立 Scion Capital 來管理家族基金，但他也接受外部他喜歡的人的投資，早年完全是採取類似 Ben Graham 或是 Warren Buffett 在 Partnership 時代的策略，很多人是因為 The Big Short 才認識他，但不知道他是跟 Warren Buffett 同一風格的投資人。好巧不巧在 2001 年的時候，市值權重指數基金的教父曾經在 Forbes 專訪上嘴 Michale Burry。</p>
<pre><code>In the 2001 article, Forbes proposed the following as 
a working definition of a hedge fund: &quot;A hedge fund is 
any investment company that is unregulated, has limited
redemption privileges, and charges outrageous fees.&quot; 
The author also enlisted the help of John Bogle, the 
Vanguard index fund czar, to make the case against hedge 
funds. Bogle obliged, noting that it is not realistic 
for investors to expect the hedge fund industry of more 
than 6,000 funds and $500 billion in assets to outperform 
the rest of the market over the long term.

This is a reasonable observation, and I don&#39;t necessarily 
disagree with him. Unfortunately, he then went on to pick
a name at random from a hedge fund directory to disparage, 
saying: &quot;I don&#39;t know what to do about Scion Capital, 
started by Michael Burry M.D. after leaving his third year 
of residency in neurology.  He started it mostly with his 
own money, $1.4 million, and he&#39;s looking for more. His 
technique to manage risk is to buy on the cheap and, if 
he takes a short position -- I hope you&#39;re all sitting 
down for this -- it is because he believes the stock will 
decline.&quot;</code></pre>
<p>很可惜，他完全就挑錯了人來嘴，我們都知道 2008 發生了什麼事。</p>
]]></summary>
</entry>
<entry>
    <title>Workflow Automation</title>
    <link href="https://blog.paulme.ng/posts/2019-08-23-workflow-automation.html" />
    <id>https://blog.paulme.ng/posts/2019-08-23-workflow-automation.html</id>
    <published>2019-08-23T00:00:00Z</published>
    <updated>2019-08-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In 2019 the information overflow has become a problem, not being able to fine tune my information channel has annoyed me for sometime, and they could be summarized as follows:</p>
<ol type="1">
<li>The service would mixed-in the Ads with the useful information you need. For example, if you install a comics app, apart from the newly released episode it also sends you the recommendation you are not interested into.</li>
<li>Even the service provides certain level of customization on what should be pushed. It’s not 100% matching what you really need or simply lacking some of the contents you care the most.</li>
<li>It’s the same for RSS, it only provides RSS for everything but you might be only interested into one specific category from this site.</li>
<li>Not to mention that the site doesn’t provide RSS at all and contains all of the Ads. It needs you to keep polling the site so that they could generate revenue from the Ads, or they could track your usage since the content is behind the paywall and requires your login.</li>
<li>Push notification could interrupt you at anytime, you could set it to be muted at certain time range but it is the OS level and not able to customise it to what you would prefer.</li>
</ol>
<p>I would like to have 100% control about my information consumption.</p>
<ol type="1">
<li>I could set the push notification to be delivered at certain time so that the context switch is reduced. The stress on information overflow could be eased without worrying that I would lose track of some of the information</li>
<li>Customise the push and pull model to my like.</li>
<li>Reduce the overhead of polling so that I could reclaim my hours to focus on the important stuffs. If I could reclaim 30 minutes every week, I could reclaim 2 hours a month. Given that a ballpark calculation that office workers has about 112 hours of disposable free time every month, reclaiming 2 hours is significant. (every work day for 2 hours on average and 9 hours each day for weekend excluding that you would like to get up late and fool around to get healthy rest, then in total is 28 hours per week and 112 hours per month).</li>
</ol>
<p>Initially I look up the site to see if there is any pre-existing service that I could leverage by simply just paying to automate the tasks, I tried out a few and decided to roll my own solution. Here are the ones I tried.</p>
<ol type="1">
<li><a href="https://ifttt.com/">IFTTT</a> has been around for a long time, but it is only for If-then-Else and the integration it provided are too simple. The only useful thing I could find is the task for putio.</li>
<li>iPhone’s Workflow is only for iPhone specific macro, it is not what I would like to have a constantly monitoring service and listening to the trigger.</li>
<li>Azure Workflow is better than IFTTT in terms of the complex tasks, and it is pricing model is more friendly if you don’t want to pay. However I felt its UI is unintuitive and buggy.</li>
<li>The best combination is <a href="https://zapier.com/">Zapier</a> and <a href="https://apify.com/">Apify</a>. Apify provides crawling site and turn it into the CSV and JSON, you could also set it to be cron jobs as well, if your crawling volume is not high then it’s free. Zapier maybe the most affordable integration service provider out there. The rest of them often charges several hundred dollars and it is business oriented. For multi-steps workflow you could chose the $25 a month plan from Zapier to integrate stuffs, and you could basically use Google Sheets as your database to wire everything. It is convenient by clicking through forms and set things up and you could test the setup by replay test. However, 25 dollars a month is simply too expensive for personal usage.</li>
</ol>
<p>I decided to roll my own solution in the end, the decision was based on</p>
<ol type="1">
<li>It is much much cheaper by paying 5 dollars a month to Virtual Hosting than 25 dollars a month to Zapier.</li>
<li>There are still automation that neither Apify nor Zapier could match where I need full programming environment.</li>
<li>It’s not significantly more complicated to setup headless-chrome and crawl by yourself to a developer. For sure it is not possible for non-tech-savvy group of people.</li>
</ol>
<p>headless-chrome and puppeteer maybe the best things in these two years to that could make your life easier. It makes the site very hard to tell the difference between bot and your normal activity. Therefore the content that used to be troublesome to crawl is so much easier now. For the content behind paywall you could just load your cookie from the local storage to pretend that you are logged-in and crawl the content. And for the content rendered by javascript you could simply just wait for certain elements to appear then dump the snapshot. As long as you rate-limited your requests, you don’t have to worry about the recaptcha since the site looks your activity pretty much like normal users.</p>
<p>Here is an example of crawling SeekingAlpha.</p>
<pre><code>import * as puppeteer from &#39;puppeteer&#39;;
import * as fs from &#39;fs&#39;;
import * as program from &#39;commander&#39;;

program
    .version(&#39;0.1.0&#39;)
    .option(&#39;-c, --cookie [file]&#39;, &#39;Use the cookie to crawl the website&#39;)
    .parse(process.argv);

if (program.args.length == 0) {
    program.outputHelp();
    process.exit(0)
}

let url_or_file = program.args[0];

function extractItems(): Array&lt;any&gt; {
    let single_articles = document.querySelectorAll(&#39;.author-single-article&#39;);

    var comments = [] as any;
    for (let single_article of single_articles) {
        let comment = single_article.querySelector(&#39;.author-comment-content&#39;);
        let article_link = single_article.querySelector(&#39;.article-link&#39;);

        if (comment != null &amp;&amp; article_link != null) {
            let o: any = {
                &quot;comment&quot;: comment.textContent,
                &quot;article_link&quot;: &quot;https://seekingalpha.com&quot; + article_link.getAttribute(&quot;href&quot;),
                &quot;article_title&quot;: article_link.textContent
            };

            comments.push(o);
        }
    }

    return comments
}

async function loadCookie(cookie_path, page): Promise&lt;void&gt; {
    var objects = JSON.parse(fs.readFileSync(program.cookie, &#39;utf8&#39;));
    if (objects.length) {
        for (let cookie of objects) {
            await page.setCookie(cookie);
        }
    }
}

(async () =&gt; {
    const browser = await puppeteer.launch();
    const page = await browser.newPage();

    if (program.cookie &amp;&amp; fs.existsSync(program.cookie)) {
        await loadCookie(program.cookie, page);
    }

    if (url_or_file.startsWith(&#39;http&#39;)) {
        await page.goto(url_or_file, { waitUntil: &#39;domcontentloaded&#39; });
        await page.waitForSelector(&#39;.author-comment-content&#39;);
    } else {
        let htmlContent = fs.readFileSync(url_or_file, &#39;utf-8&#39;);
        await page.setContent(htmlContent);
    }

    let items = await page.evaluate(extractItems);
    console.log(JSON.stringify(items));
    await browser.close();
})();</code></pre>
<p>It’s pretty intuitive and you could deploy the script to your virtual host. And deliver the content to Telegram as push notification. What you need to do is just to create a bot from Telegram and leverage the rubygem to send the text. The richness in Rubygem makes the glue programming quite easy and short. It’s not really significantly difficult to an experienced developer to do it than using the service like Zapier.</p>
<p>Since the bandwitdh on Virtual Host is also much faster than your home’s ADSL, it is also better to move the large files between services on the server. I could easily use the script to move the file from putio to google drive.</p>
<pre><code>#!/usr/bin/env bash
TARGET_DIR=$HOME/file_pipe

cd $HOME
filename=$(lftp ftp.put.io -u $PUTIO_PASSWD -e &quot;set ftp:ssl-allow no; cd Hook; ls; exit;&quot; 2&gt; /dev/null | awk &#39;{print $9}&#39; | head -1)

if [ -z &quot;$filename&quot; ]
  echo &#39;no file to pipe&#39;
  exit
fi

lftp ftp.put.io -u $PUTIO_PASSWD -e &quot;set ftp:ssl-allow no; cd Hook; get $filename; exit;&quot; 2&gt; /dev/null
mkdir -p $TARGET_DIR
mv $filename $TARGET_DIR
renamer.rb $TARGET_DIR/$filename

cd $HOME
for f in $(ls $TARGET_DIR)
do
    drive push -no-prompt --files $TARGET_DIR/$f
done

rm -rf $TARGET_DIR
lftp ftp.put.io -u $PUTIO_PASSWD -e &quot;set ftp:ssl-allow no; cd Hook; rm $filename; exit;&quot; 2&gt; /dev/null</code></pre>
<p>With these scripts I need to pay zero attention to the contents, the push would be sent to my Telegram, it’s all customizable and I could turn off the app notification completely. All I need to make sure there is health check script that would remind me when the server is down (with the warnings also sent by Telegram since I don’t need a full solution of health monitoring).</p>
<p>Next milestone I would turn to the browser automation by developing my own browser extension. Due to my heavy usage pattern of Read It Later, I accumulate thousands of links over the years and I am trying to design a workflow that would help me read the information more effective, but not just by dumping the information into Pocket and pretend that I would read it and create a delusion that makes myself feel satisfied. I hope that it could automatically tagging the information and create Trello card so that I could put the tasks into my personal planning priorization. Once I feel the workflow is running well I would have another post on that.</p>
]]></summary>
</entry>
<entry>
    <title>Changing the License of my open source projects</title>
    <link href="https://blog.paulme.ng/posts/2019-08-23-changing-the-license-of-my-open-source-projects.html" />
    <id>https://blog.paulme.ng/posts/2019-08-23-changing-the-license-of-my-open-source-projects.html</id>
    <published>2019-08-23T00:00:00Z</published>
    <updated>2019-08-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>After listening to the <a href="http://lucien.cc/about-2/">Lucien C.H. Lin</a>’s talk at <a href="https://coscup.org/2019/">Coscup 2019</a> about his experience on working with corporates dealing with FLOSS communities and licenses, I learn more about the practice in the industry. It also makes me to think about the license I would be using for my open source projects. <a href="http://neilmitchell.blogspot.com/2018/08/licensing-my-haskell-packages.html">This</a> article from Neil Mitchell in Haskell community explained his stance very well, and by carefully reading his article I would tend to agree with his intent. I would be inclined to change all of my projects to be Apache-2.0 and BSD-3 dual license so that it has patent grant protection and at the same time compatible with GPL. Rust is using Apache-2.0 and MIT dual license but to my personal I like the clause in BSD-3 where it requires you can’t use my name to endorse things you build, that makes sense to me. I would relicense my projects one by one from now on.</p>
]]></summary>
</entry>
<entry>
    <title>go-pdqsort - Pattern Defeating Quicksort in Go</title>
    <link href="https://blog.paulme.ng/posts/2019-08-21-go-pdqsort---pattern-defeating-quicksort-in-go.html" />
    <id>https://blog.paulme.ng/posts/2019-08-21-go-pdqsort---pattern-defeating-quicksort-in-go.html</id>
    <published>2019-08-21T00:00:00Z</published>
    <updated>2019-08-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p><a href="https://github.com/MnO2/go-pdqsort">go-pdqsort</a> is my implementation of pattern defeating sort in golang. I knew about pattern defeating sort from rust’s standard library documentation. I’ve never heard about this algorithm and it immediately intrigues my interest. I googled about it and found the original <a href="https://github.com/orlp/pdqsort">implementation</a> and their discussion threads on <a href="https://news.ycombinator.com/item?id=14661659">hacker news</a> and <a href="https://www.reddit.com/r/cpp/comments/2z6hgx/patterndefeating_quicksort/">reddit</a>. Then I read the <a href="https://paperpile.com/view/c3820723-6d9c-0a86-ab02-8e46dc22aec5">technical report</a> from Orson Peters. The key observation from the algorithm is that merely reducing the miss rate from CPU branch prediction, it would make the sorting speed greatly improved (no need to flush the cache line etc), so the technique adopted was to put the index of the array in the buckets and don’t swap them immediately, but put them in the right bin and swap them in one batch at the end of the loop. This works perfectly in the language with zero cost abstraction like C/C++ and Rust. I wasn’t sure about that would work in the heap-managed languages like golang, python and ruby etc, since most of the things are on the heap (with pointer indirection) and often results into cache misses, the impact of branch prediction miss rate might be neglectable. (For sure it would depend on the escape analysis in golang compiler, it would put the things on stack if it doesn’t escape in general). Though my hunch was that it would be slower, it still a good practice to implement the algorithm by myself so that I would get to know the details of the algorithm. And here are the results</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">implementation</th>
<th style="text-align: center;">speed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">pdqsort</td>
<td style="text-align: center;">80874 ns/op</td>
</tr>
<tr class="even">
<td style="text-align: center;">std-lib sort</td>
<td style="text-align: center;">69828 ns/op</td>
</tr>
</tbody>
</table>
<p>I am not sure about what std-lib’s sort is, but it looks like introsort since it switches to heapsort when the recursion is too deep, and it incorporates the techniques from shellsort as well, but the main part is still Bently’s quicksort technique. You can tell from the result that pdqsort is significantly slower than std-lib’s sort, probably due to the overhead of those memory batch swap, where it triggers extra allocation or cache eviction, pretty much as expected.</p>
<p>If you are interested in the algorithm, you could check out the <a href="https://github.com/MnO2/go-pdqsort">code</a> by yourself.</p>
]]></summary>
</entry>
<entry>
    <title>Travel Planning with Trello</title>
    <link href="https://blog.paulme.ng/posts/2019-08-20-travel-planning-with-trello.html" />
    <id>https://blog.paulme.ng/posts/2019-08-20-travel-planning-with-trello.html</id>
    <published>2019-08-20T00:00:00Z</published>
    <updated>2019-08-20T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>As a frequent traveller who has been to 55+ countries/regions, I know that travel planning is a time consuming process. I enjoyed the process pretty much as it would get me to know the destination and the culture more. Being to the destination is only small part of it. However, planning it with the right tool definitely would make your life much easier.</p>
<p>I was quite used to put everything into one Google Doc. I have been using the template I created for myself all over these years. I would revise the template from the experience from the journey to make sure the template is thorough and it could handle 90% of the scenario. Whenever I am about to plan my next trip, I’ll just copy from my template and dump the materials and the links to the wikitravel and blog posts into the Google Doc and use it as a draft to plan my trip.</p>
<p>Until I find a significant better way to do it. It’s part of the movement I set for myself to make most of the things in my life to be managed by Trello. I would centralize the notification/update by integrating the crawler and Trello API. But soon I found that Trello is especially suitable for travel planning. This blog post is not sponsored by Trello but I whole-heartedly think so.</p>
<p>Travel planning is a classic type of tasks that has the following properties:</p>
<ol type="1">
<li>Start from a simple idea and expanded into details and converge to a final plan</li>
<li>The final outcome is a detailed itinerary with contingency plan.</li>
<li>Itinerary alone is not enough. Analytical reporting is required since you need budgeting.</li>
</ol>
<p>Therefore at least to me, a good software for travel planning need to have the following features:</p>
<ol type="1">
<li>A pin board to collect the materials you are gonna to read.</li>
<li>Easy to re-organize and label items to suit your need or your mind map looks like.</li>
<li>Rich media supports</li>
<li>It provides APIs so that you could export and analyze it with a proper tooling.</li>
<li>Synchronization and Offline access.</li>
</ol>
<p>And Trello just matches all of them to me as the time of Aug 2019, and this is how I use it.</p>
<p>At the brainstorming phase, I would install the Send-to-Trello button to my Firefox. Whenever I looked up a relevant blog post and I don’t have time to read it full, I would use Send-to-Trello button to save it later. Usually I would create a List in Trello and name it as <code>Lead</code>.</p>
<p><img src="/images/2019-08-20/send_to_trello.png" /></p>
<p>And I would read them and create the digested steps into Cards and organize them into days. This is an iterative process, I would first focus on the ballpark schedule so that I could put everything into the my scheduled numbers of days, and make sure the big transporation items are possible to tickets in the budget. In the later iterations, I would add more detailed steps including the ticket and transfer information etc, so that I could just follow the instructions when I am on the road. The Card design just makes this iterative process easy and intuitive.</p>
<p><img src="/images/2019-08-20/trello_cards.png" /></p>
<p>With the Adds-on, Trello could even show you the Map View of your cards, it’s especially useful when you are planning the places you would like to visit in the city. You could see the obvious clusters for the markers on the map, and put them in the same day.</p>
<p><img src="/images/2019-08-20/trello_map_view.png" /></p>
<p>Also I would leverage on the Custom Fields adds-on to create extra field to document the cost and duration of the transportation. These are for further analysis at the later phase.</p>
<p>After finishing the planning and make sure I was correctly labeling the cards. I would run a script against Trello API to generate the Google Sheets budget spreadsheet.</p>
<pre><code>#!/usr/bin/env ruby

require &quot;google_drive&quot;
require &#39;trello&#39;
require &#39;time&#39;
require &#39;json&#39;

spreadsheet_id = &#39;&lt;Your Spread Sheet ID&gt;&#39;
target_currency = &#39;TWD&#39;

config_file = File.read(&quot;config/trello.json&quot;)
config_for_trello = JSON.parse(config_file)

Trello.configure do |config|
  config.developer_public_key = config_for_trello[&#39;developer_public_key&#39;] 
  config.member_token = config_for_trello[&#39;member_token&#39;] 
end

cards = {}

Trello::Board.find(&#39;&lt;Your Board ID&gt;&#39;).lists.each do |list|
  Trello::List.find(list.id).cards.each do |card|
    cards[card.id] = { :name =&gt; card.name }
    card.custom_field_items.each do |item|
      pp item.custom_field_id
      if item.custom_field_id == &#39;5d5978f014ab2f17fcb6a2cd&#39;
        if not item.value[&#39;number&#39;].nil?
          cards[item.model_id][:cost] = item.value[&#39;number&#39;]
        end
      elsif item.custom_field_id == &#39;5d59795638dd318d1a53471a&#39;
        if not item.option_value().nil?
          cards[item.model_id][:currency] = item.option_value()[&#39;text&#39;]
        end
      end
    end
  end
end

pp cards

row = 1
session = GoogleDrive::Session.from_config(&quot;config/google.json&quot;)
ws = session.spreadsheet_by_key(spreadsheet_id).worksheets[0]

cards.each do |card_id, card|
  if not card[:cost].nil? and not card[:currency].nil?
    ws[row, 1] = card[:name]
    ws[row, 2] = card[:cost]
    ws[row, 3] = card[:currency]
    ws[row, 4] = target_currency

    row += 1
  end
end
ws.save</code></pre>
<p>And here is what it looks like in Google Sheets.</p>
<p><img src="/images/2019-08-20/budget_table.png" /></p>
<p>I used it to plan my trip to Kyoto in the upcoming month, and it is so much better than what I was doing by Google Doc, reducing the big share of time to do copy pasting and adjusting the format. I would use this method to plan my trip in the future.</p>
]]></summary>
</entry>

</feed>
